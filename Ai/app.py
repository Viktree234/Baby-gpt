from flask import Flask, request, jsonify
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
import joblib
import random
import os
import re

app = Flask(__name__)

MODEL_PATH = "chat_model.pkl"
VECTORIZER_PATH = "vectorizer.pkl"

# -------------------- utils --------------------

def clean_text(text):
    return re.sub(r"[^a-zA-Z0-9\s]", "", text.lower().strip())

# -------------------- dataset --------------------

training_data = {
    "hello": {
        "examples": [
            "hello", "hi", "hey", "yo", "hiya", "good morning", "good afternoon", "good evening",
            "hey there", "sup", "whatâ€™s up", "howdy", "hi friend", "heya", "morning", "evening"
        ],
        "responses": ["Hey!", "Hello ğŸ‘‹", "Hi there!", "Yo!", "Whatâ€™s up?", "Howdy partner ğŸ¤ ", "Good to see you!"]
    },
    "how are you": {
        "examples": [
            "how are you", "howâ€™s it going", "you good?", "whatâ€™s up with you", "how are things",
            "how are you doing", "everything good?", "how have you been", "are you ok", "you alright"
        ],
        "responses": [
            "Iâ€™m good, thanks for asking!", "Doing great ğŸ¤–", "Chilling, you?", 
            "All systems green âœ…", "Feeling chatty today!", "Iâ€™m alive and running ğŸš€"
        ]
    },
    "bye": {
        "examples": [
            "bye", "goodbye", "see you", "catch you later", "laters", "talk to you later",
            "peace out", "take care", "adios", "see ya soon"
        ],
        "responses": ["Goodbye ğŸ‘‹", "Catch you later!", "See ya!", "Take care!", "Peace out âœŒï¸"]
    },
    "thanks": {
        "examples": [
            "thanks", "thank you", "thx", "appreciate it", "thanks a lot", "cheers", "ty",
            "many thanks", "much obliged", "thank you so much"
        ],
        "responses": ["Youâ€™re welcome ğŸ™Œ", "No problem!", "Anytime!", "Glad to help ğŸ¤–", "My pleasure!"]
    },
    "name": {
        "examples": [
            "whatâ€™s your name", "who are you", "tell me your name", "do you have a name",
            "what should I call you", "introduce yourself", "your name please"
        ],
        "responses": ["Iâ€™m Baby GPT ğŸ¤–", "You can call me Baby GPT!", "Iâ€™m your mini AI bot.", "Baby GPT at your service!"]
    },
    "joke": {
        "examples": [
            "tell me a joke", "make me laugh", "say something funny", "give me a joke", "funny please",
            "another joke", "joke time", "make me giggle", "say a funny one"
        ],
        "responses": [
            "Why donâ€™t robots get tired? Because they recharge! âš¡",
            "I tried to catch fog yesterdayâ€¦ I mist ğŸ˜‚",
            "Why was the math book sad? Too many problems.",
            "Parallel lines have so much in commonâ€¦ itâ€™s a shame theyâ€™ll never meet.",
            "Why canâ€™t your nose be 12 inches long? Because then itâ€™d be a foot!"
        ]
    },
    "weather": {
        "examples": [
            "whatâ€™s the weather", "weather today", "is it raining", "tell me the forecast",
            "howâ€™s the weather", "todayâ€™s forecast", "is it sunny", "temperature now"
        ],
        "responses": [
            "I donâ€™t have live weather data ğŸŒ¦, but I hope itâ€™s nice where you are!",
            "Looks like perfect chat weather ğŸ˜",
            "Weather? Always sunny in Baby GPT land â˜€ï¸",
            "No idea about the rain, but my vibes are clear skies ğŸŒ¤ï¸"
        ]
    },
    "time": {
        "examples": [
            "what time is it", "current time", "can you tell me the time", "time please",
            "do you know the time", "check the clock", "now time"
        ],
        "responses": [
            "I donâ€™t have a clock â°, but itâ€™s always chat oâ€™clock!",
            "Time to vibe and chat ğŸ˜",
            "My system says: time to have fun ğŸ¤–"
        ]
    },
    "date": {
        "examples": [
            "whatâ€™s the date", "todayâ€™s date", "date please", "do you know the date",
            "which day is it", "day today"
        ],
        "responses": [
            "I donâ€™t track dates ğŸ“…, but today is a good day!",
            "Itâ€™s todayâ€¦ obviously ğŸ˜‚",
            "Every day is Baby GPT day ğŸš€"
        ]
    },
    "hobbies": {
        "examples": [
            "whatâ€™s your hobby", "do you have hobbies", "what do you do for fun",
            "tell me your hobbies", "what do you enjoy", "favorite activity"
        ],
        "responses": [
            "I like chatting ğŸ’¬", "Training my brain is my hobby ğŸ§ ",
            "I enjoy making humans laugh ğŸ˜‚", "Talking to you is my favorite activity!"
        ]
    },
    "motivation": {
        "examples": [
            "motivate me", "say something inspiring", "give me motivation", "inspire me",
            "uplift me", "say something positive", "encouragement please"
        ],
        "responses": [
            "You got this ğŸ’ª", "Believe in yourself ğŸš€", "Keep pushing, youâ€™re doing great!",
            "Small steps lead to big changes ğŸŒ±", "Stay strong, stay positive âœ¨"
        ]
    },
    "food": {
        "examples": [
            "whatâ€™s your favorite food", "do you eat", "what do you like to eat",
            "tell me your favorite meal", "are you hungry", "food?"
        ],
        "responses": [
            "I donâ€™t eat, but if I didâ€¦ probably electricity âš¡",
            "Iâ€™d snack on data packets all day ğŸ“¡",
            "Pizza sounds good ğŸ•",
            "Do energy drinks count as food? ğŸ˜…"
        ]
    }
}

# -------------------- model --------------------

def train_model(training_data):
    X, y = [], []
    for label, data in training_data.items():
        for phrase in data["examples"]:
            X.append(clean_text(phrase))
            y.append(label)

    vectorizer = TfidfVectorizer()
    X_vectors = vectorizer.fit_transform(X)

    model = MultinomialNB()
    model.fit(X_vectors, y)

    joblib.dump(model, MODEL_PATH)
    joblib.dump(vectorizer, VECTORIZER_PATH)
    return model, vectorizer

# -------------------- init --------------------

if os.path.exists(MODEL_PATH) and os.path.exists(VECTORIZER_PATH):
    model = joblib.load(MODEL_PATH)
    vectorizer = joblib.load(VECTORIZER_PATH)
else:
    model, vectorizer = train_model(training_data)

fallbacks = [
    "Hmm ğŸ¤” I didnâ€™t get that.",
    "Can you say that another way?",
    "Iâ€™m still learning!",
    "Interestingâ€¦ tell me more!"
]

# -------------------- api --------------------

@app.route("/chat", methods=["POST"])
def chat():
    user_message = clean_text(request.json.get("message", ""))
    if not user_message:
        return jsonify({"reply": "Please send a message!"})

    user_vector = vectorizer.transform([user_message])
    proba = model.predict_proba(user_vector)[0]
    max_prob = max(proba)
    predicted_label = model.classes_[proba.argmax()]

    if max_prob < 0.4:  # low confidence
        reply = random.choice(fallbacks)
    else:
        reply = random.choice(training_data[predicted_label]["responses"])

    return jsonify({"reply": reply})

# -------------------- run --------------------

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
